<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>sedna.core.lifelong_learning.lifelong_learning API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sedna.core.lifelong_learning.lifelong_learning</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Copyright 2021 The KubeEdge Authors.
#
# Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import tempfile

import joblib

from sedna.backend import set_backend
from sedna.core.base import JobBase
from sedna.common.file_ops import FileOps
from sedna.common.constant import K8sResourceKind, K8sResourceKindStatus
from sedna.common.config import Context
from sedna.common.class_factory import ClassType, ClassFactory
from sedna.algorithms.multi_task_learning import MulTaskLearning
from sedna.service.client import KBClient


class LifelongLearning(JobBase):
    &#34;&#34;&#34;
    Lifelong learning
    &#34;&#34;&#34;

    def __init__(self,
                 estimator,
                 task_definition=None,
                 task_relationship_discovery=None,
                 task_mining=None,
                 task_remodeling=None,
                 inference_integrate=None,
                 unseen_task_detect=None):
        &#34;&#34;&#34;
        Initial a lifelong learning job
        :param estimator: Customize estimator
        :param task_definition: dict, {&#34;method&#34;: &#34;&#34;, param: &#34;&#34;} Multitask definition base on given traning samples
        :param task_relationship_discovery: dict, {&#34;method&#34;: &#34;&#34;, param: &#34;&#34;}  Discover the relation of tasks which generated from task_definition  # noqa
        :param task_mining:  dict, {&#34;method&#34;: &#34;&#34;, param: &#34;&#34;} Mining target tasks of inference samples
        :param task_remodeling:  dict, {&#34;method&#34;: &#34;&#34;, param: &#34;&#34;} Remodeling tasks
        :param inference_integrate:  dict, {&#34;method&#34;: &#34;&#34;, param: &#34;&#34;} Integrating algorithm for the output geted by multitask inference  # noqa
        :param unseen_task_detect:  dict, {&#34;method&#34;: &#34;&#34;, param: &#34;&#34;} unseen task detect
        &#34;&#34;&#34;

        if not task_definition:
            task_definition = {
                &#34;method&#34;: &#34;TaskDefinitionByDataAttr&#34;
            }
        if not unseen_task_detect:
            unseen_task_detect = {
                &#34;method&#34;: &#34;TaskAttrFilter&#34;
            }
        e = MulTaskLearning(
            estimator=estimator,
            task_definition=task_definition,
            task_relationship_discovery=task_relationship_discovery,
            task_mining=task_mining,
            task_remodeling=task_remodeling,
            inference_integrate=inference_integrate)
        self.unseen_task_detect = unseen_task_detect.get(&#34;method&#34;,
                                                         &#34;TaskAttrFilter&#34;)
        self.unseen_task_detect_param = e.parse_param(
            unseen_task_detect.get(&#34;param&#34;, {})
        )
        config = dict(
            ll_kb_server=Context.get_parameters(&#34;KB_SERVER&#34;),
            output_url=Context.get_parameters(&#34;OUTPUT_URL&#34;, &#34;/tmp&#34;)
        )
        task_index = FileOps.join_path(config[&#39;output_url&#39;], &#39;index.pkl&#39;)
        config[&#39;task_index&#39;] = task_index
        super(LifelongLearning, self).__init__(
            estimator=e, config=config
        )
        self.job_kind = K8sResourceKind.LIFELONG_JOB.value
        self.kb_server = KBClient(kbserver=self.config.ll_kb_server)

    def train(self, train_data,
              valid_data=None,
              post_process=None,
              action=&#34;initial&#34;,
              **kwargs):
        &#34;&#34;&#34;
        :param train_data: data use to train model
        :param valid_data: data use to valid model
        :param post_process: callback function
        :param action: initial - kb init, update - kb incremental update
        &#34;&#34;&#34;

        callback_func = None
        if post_process is not None:
            callback_func = ClassFactory.get_cls(
                ClassType.CALLBACK, post_process)
        res = self.estimator.train(
            train_data=train_data,
            valid_data=valid_data,
            **kwargs
        )  # todo: Distinguishing incremental update and fully overwrite

        task_index_url = self.estimator.estimator.task_index_url
        task_index = joblib.load(task_index_url)

        extractor = task_index[&#39;extractor&#39;]
        task_groups = task_index[&#39;task_groups&#39;]

        model_upload_key = {}
        for task in task_groups:
            model_file = task.model.model
            save_model = FileOps.join_path(
                self.config.output_url,
                os.path.basename(model_file)
            )
            if model_file not in model_upload_key:
                model_upload_key[model_file] = FileOps.upload(model_file,
                                                              save_model)
            model_file = model_upload_key[model_file]

            try:
                model = self.kb_server.upload_file(save_model)
            except Exception as err:
                self.log.error(
                    f&#34;Upload task model of {model_file} fail: {err}&#34;
                )
                model_obj = set_backend(
                    estimator=self.estimator.estimator.base_model
                )
                model = model_obj.load(model_file)
            task.model.model = model

            for _task in task.tasks:
                sample_dir = FileOps.join_path(
                    self.config.output_url,
                    f&#34;{_task.samples.data_type}_{_task.entry}.sample&#34;)
                task.samples.save(sample_dir)
                try:
                    sample_dir = self.kb_server.upload_file(sample_dir)
                except Exception as err:
                    self.log.error(
                        f&#34;Upload task samples of {_task.entry} fail: {err}&#34;)
                _task.samples.data_url = sample_dir

        task_info = {
            &#34;task_groups&#34;: task_groups,
            &#34;extractor&#34;: extractor
        }
        fd, name = tempfile.mkstemp()
        joblib.dump(task_info, name)

        index_file = self.kb_server.update_db(name)
        if not index_file:
            self.log.error(f&#34;KB update Fail !&#34;)
            index_file = name
        FileOps.upload(index_file, self.config.task_index)

        task_info_res = self.estimator.model_info(
            self.config.task_index, result=res,
            relpath=self.config.data_path_prefix)
        self.report_task_info(
            None, K8sResourceKindStatus.COMPLETED.value, task_info_res)
        self.log.info(f&#34;Lifelong learning Train task Finished, &#34;
                      f&#34;KB idnex save in {self.config.task_index}&#34;)
        return callback_func(self.estimator, res) if callback_func else res

    def update(self, train_data, valid_data=None, post_process=None, **kwargs):
        return self.train(
            train_data=train_data,
            valid_data=valid_data,
            post_process=post_process,
            action=&#34;update&#34;,
            **kwargs
        )

    def evaluate(self, data, post_process=None, **kwargs):
        &#34;&#34;&#34;
        Evaluate task for LifelongLearning
        :param data: datasource use for evaluation
        :param post_process: post process
        :param kwargs: params for evaluate of customize estimator
        :return: evaluate metrics
        &#34;&#34;&#34;
        callback_func = None
        if callable(post_process):
            callback_func = post_process
        elif post_process is not None:
            callback_func = ClassFactory.get_cls(
                ClassType.CALLBACK, post_process)
        task_index_url = self.get_parameters(
            &#34;MODEL_URLS&#34;, self.config.task_index)
        index_url = self.estimator.estimator.task_index_url
        self.log.info(
            f&#34;Download kb index from {task_index_url} to {index_url}&#34;)
        FileOps.download(task_index_url, index_url)
        res, tasks_detail = self.estimator.evaluate(data=data, **kwargs)
        drop_tasks = []

        model_filter_operator = self.get_parameters(&#34;operator&#34;, &#34;&gt;&#34;)
        model_threshold = float(self.get_parameters(&#39;model_threshold&#39;, 0.1))

        operator_map = {
            &#34;&gt;&#34;: lambda x, y: x &gt; y,
            &#34;&lt;&#34;: lambda x, y: x &lt; y,
            &#34;=&#34;: lambda x, y: x == y,
            &#34;&gt;=&#34;: lambda x, y: x &gt;= y,
            &#34;&lt;=&#34;: lambda x, y: x &lt;= y,
        }
        if model_filter_operator not in operator_map:
            self.log.warn(
                f&#34;operator {model_filter_operator} use to &#34;
                f&#34;compare is not allow, set to &lt;&#34;
            )
            model_filter_operator = &#34;&lt;&#34;
        operator_func = operator_map[model_filter_operator]

        for detail in tasks_detail:
            scores = detail.scores
            entry = detail.entry
            self.log.info(f&#34;{entry} scores: {scores}&#34;)
            if any(map(lambda x: operator_func(float(x),
                                               model_threshold),
                       scores.values())):
                self.log.warn(
                    f&#34;{entry} will not be deploy because all &#34;
                    f&#34;scores {model_filter_operator} {model_threshold}&#34;)
                drop_tasks.append(entry)
                continue
        drop_task = &#34;,&#34;.join(drop_tasks)
        index_file = self.kb_server.update_task_status(drop_task, new_status=0)
        if not index_file:
            self.log.error(f&#34;KB update Fail !&#34;)
            index_file = str(index_url)
        self.log.info(
            f&#34;upload kb index from {index_file} to {self.config.task_index}&#34;)
        FileOps.upload(index_file, self.config.task_index)
        task_info_res = self.estimator.model_info(
            self.config.task_index, result=res,
            relpath=self.config.data_path_prefix)
        self.report_task_info(
            None,
            K8sResourceKindStatus.COMPLETED.value,
            task_info_res,
            kind=&#34;eval&#34;)
        return callback_func(res) if callback_func else res

    def inference(self, data=None, post_process=None, **kwargs):
        &#34;&#34;&#34;
        Inference task for LifelongLearning
        :param data: inference sample
        :param post_process: post process
        :param kwargs: params for inference of customize estimator
        :return: inference result, if is hard sample, match tasks
        &#34;&#34;&#34;

        task_index_url = self.get_parameters(
            &#34;MODEL_URLS&#34;, self.config.task_index)
        index_url = self.estimator.estimator.task_index_url
        FileOps.download(task_index_url, index_url)
        res, tasks = self.estimator.predict(
            data=data, post_process=post_process, **kwargs
        )

        is_unseen_task = False
        if self.unseen_task_detect:

            try:
                if callable(self.unseen_task_detect):
                    unseen_task_detect_algorithm = self.unseen_task_detect()
                else:
                    unseen_task_detect_algorithm = ClassFactory.get_cls(
                        ClassType.UTD, self.unseen_task_detect
                    )()
            except ValueError as err:
                self.log.error(&#34;Lifelong learning &#34;
                               &#34;Inference [UTD] : {}&#34;.format(err))
            else:
                is_unseen_task = unseen_task_detect_algorithm(
                    tasks=tasks, result=res, **self.unseen_task_detect_param
                )
        return res, is_unseen_task, tasks</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="sedna.core.lifelong_learning.lifelong_learning.LifelongLearning"><code class="flex name class">
<span>class <span class="ident">LifelongLearning</span></span>
<span>(</span><span>estimator, task_definition=None, task_relationship_discovery=None, task_mining=None, task_remodeling=None, inference_integrate=None, unseen_task_detect=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Lifelong learning</p>
<p>Initial a lifelong learning job
<br>:param estimator: Customize estimator
<br>:param task_definition: dict, e.g. {"method": "", param: ""}<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Multitask definition base on given traning samples
<br>:param task_relationship_discovery: dict, e.g. {"method": "", param: ""}<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
Discover the relation of tasks which generated from task_definition
<br>:param task_mining:
dict, e.g. {"method": "", param: ""}<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Mining target tasks of inference samples
<br>:param task_remodeling:
dict, e.g. {"method": "", param: ""}<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Remodeling tasks
<br>:param inference_integrate:
dict, e.g. {"method": "", param: ""}<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Integrating algorithm for the output geted by multitask inference
<br>:param unseen_task_detect:
dict, e.g. {"method": "", param: ""}<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; unseen task detect</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LifelongLearning(JobBase):
    &#34;&#34;&#34;
    Lifelong learning
    &#34;&#34;&#34;

    def __init__(self,
                 estimator,
                 task_definition=None,
                 task_relationship_discovery=None,
                 task_mining=None,
                 task_remodeling=None,
                 inference_integrate=None,
                 unseen_task_detect=None):
        &#34;&#34;&#34;
        Initial a lifelong learning job
        :param estimator: Customize estimator
        :param task_definition: dict, {&#34;method&#34;: &#34;&#34;, param: &#34;&#34;} Multitask definition base on given traning samples
        :param task_relationship_discovery: dict, {&#34;method&#34;: &#34;&#34;, param: &#34;&#34;}  Discover the relation of tasks which generated from task_definition  # noqa
        :param task_mining:  dict, {&#34;method&#34;: &#34;&#34;, param: &#34;&#34;} Mining target tasks of inference samples
        :param task_remodeling:  dict, {&#34;method&#34;: &#34;&#34;, param: &#34;&#34;} Remodeling tasks
        :param inference_integrate:  dict, {&#34;method&#34;: &#34;&#34;, param: &#34;&#34;} Integrating algorithm for the output geted by multitask inference  # noqa
        :param unseen_task_detect:  dict, {&#34;method&#34;: &#34;&#34;, param: &#34;&#34;} unseen task detect
        &#34;&#34;&#34;

        if not task_definition:
            task_definition = {
                &#34;method&#34;: &#34;TaskDefinitionByDataAttr&#34;
            }
        if not unseen_task_detect:
            unseen_task_detect = {
                &#34;method&#34;: &#34;TaskAttrFilter&#34;
            }
        e = MulTaskLearning(
            estimator=estimator,
            task_definition=task_definition,
            task_relationship_discovery=task_relationship_discovery,
            task_mining=task_mining,
            task_remodeling=task_remodeling,
            inference_integrate=inference_integrate)
        self.unseen_task_detect = unseen_task_detect.get(&#34;method&#34;,
                                                         &#34;TaskAttrFilter&#34;)
        self.unseen_task_detect_param = e.parse_param(
            unseen_task_detect.get(&#34;param&#34;, {})
        )
        config = dict(
            ll_kb_server=Context.get_parameters(&#34;KB_SERVER&#34;),
            output_url=Context.get_parameters(&#34;OUTPUT_URL&#34;, &#34;/tmp&#34;)
        )
        task_index = FileOps.join_path(config[&#39;output_url&#39;], &#39;index.pkl&#39;)
        config[&#39;task_index&#39;] = task_index
        super(LifelongLearning, self).__init__(
            estimator=e, config=config
        )
        self.job_kind = K8sResourceKind.LIFELONG_JOB.value
        self.kb_server = KBClient(kbserver=self.config.ll_kb_server)

    def train(self, train_data,
              valid_data=None,
              post_process=None,
              action=&#34;initial&#34;,
              **kwargs):
        &#34;&#34;&#34;
        :param train_data: data use to train model
        :param valid_data: data use to valid model
        :param post_process: callback function
        :param action: initial - kb init, update - kb incremental update
        &#34;&#34;&#34;

        callback_func = None
        if post_process is not None:
            callback_func = ClassFactory.get_cls(
                ClassType.CALLBACK, post_process)
        res = self.estimator.train(
            train_data=train_data,
            valid_data=valid_data,
            **kwargs
        )  # todo: Distinguishing incremental update and fully overwrite

        task_index_url = self.estimator.estimator.task_index_url
        task_index = joblib.load(task_index_url)

        extractor = task_index[&#39;extractor&#39;]
        task_groups = task_index[&#39;task_groups&#39;]

        model_upload_key = {}
        for task in task_groups:
            model_file = task.model.model
            save_model = FileOps.join_path(
                self.config.output_url,
                os.path.basename(model_file)
            )
            if model_file not in model_upload_key:
                model_upload_key[model_file] = FileOps.upload(model_file,
                                                              save_model)
            model_file = model_upload_key[model_file]

            try:
                model = self.kb_server.upload_file(save_model)
            except Exception as err:
                self.log.error(
                    f&#34;Upload task model of {model_file} fail: {err}&#34;
                )
                model_obj = set_backend(
                    estimator=self.estimator.estimator.base_model
                )
                model = model_obj.load(model_file)
            task.model.model = model

            for _task in task.tasks:
                sample_dir = FileOps.join_path(
                    self.config.output_url,
                    f&#34;{_task.samples.data_type}_{_task.entry}.sample&#34;)
                task.samples.save(sample_dir)
                try:
                    sample_dir = self.kb_server.upload_file(sample_dir)
                except Exception as err:
                    self.log.error(
                        f&#34;Upload task samples of {_task.entry} fail: {err}&#34;)
                _task.samples.data_url = sample_dir

        task_info = {
            &#34;task_groups&#34;: task_groups,
            &#34;extractor&#34;: extractor
        }
        fd, name = tempfile.mkstemp()
        joblib.dump(task_info, name)

        index_file = self.kb_server.update_db(name)
        if not index_file:
            self.log.error(f&#34;KB update Fail !&#34;)
            index_file = name
        FileOps.upload(index_file, self.config.task_index)

        task_info_res = self.estimator.model_info(
            self.config.task_index, result=res,
            relpath=self.config.data_path_prefix)
        self.report_task_info(
            None, K8sResourceKindStatus.COMPLETED.value, task_info_res)
        self.log.info(f&#34;Lifelong learning Train task Finished, &#34;
                      f&#34;KB idnex save in {self.config.task_index}&#34;)
        return callback_func(self.estimator, res) if callback_func else res

    def update(self, train_data, valid_data=None, post_process=None, **kwargs):
        return self.train(
            train_data=train_data,
            valid_data=valid_data,
            post_process=post_process,
            action=&#34;update&#34;,
            **kwargs
        )

    def evaluate(self, data, post_process=None, **kwargs):
        &#34;&#34;&#34;
        Evaluate task for LifelongLearning
        :param data: datasource use for evaluation
        :param post_process: post process
        :param kwargs: params for evaluate of customize estimator
        :return: evaluate metrics
        &#34;&#34;&#34;
        callback_func = None
        if callable(post_process):
            callback_func = post_process
        elif post_process is not None:
            callback_func = ClassFactory.get_cls(
                ClassType.CALLBACK, post_process)
        task_index_url = self.get_parameters(
            &#34;MODEL_URLS&#34;, self.config.task_index)
        index_url = self.estimator.estimator.task_index_url
        self.log.info(
            f&#34;Download kb index from {task_index_url} to {index_url}&#34;)
        FileOps.download(task_index_url, index_url)
        res, tasks_detail = self.estimator.evaluate(data=data, **kwargs)
        drop_tasks = []

        model_filter_operator = self.get_parameters(&#34;operator&#34;, &#34;&gt;&#34;)
        model_threshold = float(self.get_parameters(&#39;model_threshold&#39;, 0.1))

        operator_map = {
            &#34;&gt;&#34;: lambda x, y: x &gt; y,
            &#34;&lt;&#34;: lambda x, y: x &lt; y,
            &#34;=&#34;: lambda x, y: x == y,
            &#34;&gt;=&#34;: lambda x, y: x &gt;= y,
            &#34;&lt;=&#34;: lambda x, y: x &lt;= y,
        }
        if model_filter_operator not in operator_map:
            self.log.warn(
                f&#34;operator {model_filter_operator} use to &#34;
                f&#34;compare is not allow, set to &lt;&#34;
            )
            model_filter_operator = &#34;&lt;&#34;
        operator_func = operator_map[model_filter_operator]

        for detail in tasks_detail:
            scores = detail.scores
            entry = detail.entry
            self.log.info(f&#34;{entry} scores: {scores}&#34;)
            if any(map(lambda x: operator_func(float(x),
                                               model_threshold),
                       scores.values())):
                self.log.warn(
                    f&#34;{entry} will not be deploy because all &#34;
                    f&#34;scores {model_filter_operator} {model_threshold}&#34;)
                drop_tasks.append(entry)
                continue
        drop_task = &#34;,&#34;.join(drop_tasks)
        index_file = self.kb_server.update_task_status(drop_task, new_status=0)
        if not index_file:
            self.log.error(f&#34;KB update Fail !&#34;)
            index_file = str(index_url)
        self.log.info(
            f&#34;upload kb index from {index_file} to {self.config.task_index}&#34;)
        FileOps.upload(index_file, self.config.task_index)
        task_info_res = self.estimator.model_info(
            self.config.task_index, result=res,
            relpath=self.config.data_path_prefix)
        self.report_task_info(
            None,
            K8sResourceKindStatus.COMPLETED.value,
            task_info_res,
            kind=&#34;eval&#34;)
        return callback_func(res) if callback_func else res

    def inference(self, data=None, post_process=None, **kwargs):
        &#34;&#34;&#34;
        Inference task for LifelongLearning
        :param data: inference sample
        :param post_process: post process
        :param kwargs: params for inference of customize estimator
        :return: inference result, if is hard sample, match tasks
        &#34;&#34;&#34;

        task_index_url = self.get_parameters(
            &#34;MODEL_URLS&#34;, self.config.task_index)
        index_url = self.estimator.estimator.task_index_url
        FileOps.download(task_index_url, index_url)
        res, tasks = self.estimator.predict(
            data=data, post_process=post_process, **kwargs
        )

        is_unseen_task = False
        if self.unseen_task_detect:

            try:
                if callable(self.unseen_task_detect):
                    unseen_task_detect_algorithm = self.unseen_task_detect()
                else:
                    unseen_task_detect_algorithm = ClassFactory.get_cls(
                        ClassType.UTD, self.unseen_task_detect
                    )()
            except ValueError as err:
                self.log.error(&#34;Lifelong learning &#34;
                               &#34;Inference [UTD] : {}&#34;.format(err))
            else:
                is_unseen_task = unseen_task_detect_algorithm(
                    tasks=tasks, result=res, **self.unseen_task_detect_param
                )
        return res, is_unseen_task, tasks</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sedna.core.base.JobBase" href="../base.html#sedna.core.base.JobBase">JobBase</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sedna.core.lifelong_learning.lifelong_learning.LifelongLearning.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, data, post_process=None, **eval_param)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate task for LifelongLearning
<br>:param data: datasource use for evaluation
<br>:param post_process: post process
<br>:param eval_param: params for evaluate of customize estimator
<br>:return: evaluate metrics</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, data, post_process=None, **kwargs):
    &#34;&#34;&#34;
    Evaluate task for LifelongLearning
    :param data: datasource use for evaluation
    :param post_process: post process
    :param kwargs: params for evaluate of customize estimator
    :return: evaluate metrics
    &#34;&#34;&#34;
    callback_func = None
    if callable(post_process):
        callback_func = post_process
    elif post_process is not None:
        callback_func = ClassFactory.get_cls(
            ClassType.CALLBACK, post_process)
    task_index_url = self.get_parameters(
        &#34;MODEL_URLS&#34;, self.config.task_index)
    index_url = self.estimator.estimator.task_index_url
    self.log.info(
        f&#34;Download kb index from {task_index_url} to {index_url}&#34;)
    FileOps.download(task_index_url, index_url)
    res, tasks_detail = self.estimator.evaluate(data=data, **kwargs)
    drop_tasks = []

    model_filter_operator = self.get_parameters(&#34;operator&#34;, &#34;&gt;&#34;)
    model_threshold = float(self.get_parameters(&#39;model_threshold&#39;, 0.1))

    operator_map = {
        &#34;&gt;&#34;: lambda x, y: x &gt; y,
        &#34;&lt;&#34;: lambda x, y: x &lt; y,
        &#34;=&#34;: lambda x, y: x == y,
        &#34;&gt;=&#34;: lambda x, y: x &gt;= y,
        &#34;&lt;=&#34;: lambda x, y: x &lt;= y,
    }
    if model_filter_operator not in operator_map:
        self.log.warn(
            f&#34;operator {model_filter_operator} use to &#34;
            f&#34;compare is not allow, set to &lt;&#34;
        )
        model_filter_operator = &#34;&lt;&#34;
    operator_func = operator_map[model_filter_operator]

    for detail in tasks_detail:
        scores = detail.scores
        entry = detail.entry
        self.log.info(f&#34;{entry} scores: {scores}&#34;)
        if any(map(lambda x: operator_func(float(x),
                                           model_threshold),
                   scores.values())):
            self.log.warn(
                f&#34;{entry} will not be deploy because all &#34;
                f&#34;scores {model_filter_operator} {model_threshold}&#34;)
            drop_tasks.append(entry)
            continue
    drop_task = &#34;,&#34;.join(drop_tasks)
    index_file = self.kb_server.update_task_status(drop_task, new_status=0)
    if not index_file:
        self.log.error(f&#34;KB update Fail !&#34;)
        index_file = str(index_url)
    self.log.info(
        f&#34;upload kb index from {index_file} to {self.config.task_index}&#34;)
    FileOps.upload(index_file, self.config.task_index)
    task_info_res = self.estimator.model_info(
        self.config.task_index, result=res,
        relpath=self.config.data_path_prefix)
    self.report_task_info(
        None,
        K8sResourceKindStatus.COMPLETED.value,
        task_info_res,
        kind=&#34;eval&#34;)
    return callback_func(res) if callback_func else res</code></pre>
</details>
</dd>
<dt id="sedna.core.lifelong_learning.lifelong_learning.LifelongLearning.inference"><code class="name flex">
<span>def <span class="ident">inference</span></span>(<span>self, data=None, post_process=None, **infer_param)</span>
</code></dt>
<dd>
<div class="desc"><p>Inference task for LifelongLearning
<br>:param data: inference sample
<br>:param post_process: post process
<br>:param infer_param: params for inference of customize estimator
<br>:return: inference result, if is hard sample, match tasks</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def inference(self, data=None, post_process=None, **kwargs):
    &#34;&#34;&#34;
    Inference task for LifelongLearning
    :param data: inference sample
    :param post_process: post process
    :param kwargs: params for inference of customize estimator
    :return: inference result, if is hard sample, match tasks
    &#34;&#34;&#34;

    task_index_url = self.get_parameters(
        &#34;MODEL_URLS&#34;, self.config.task_index)
    index_url = self.estimator.estimator.task_index_url
    FileOps.download(task_index_url, index_url)
    res, tasks = self.estimator.predict(
        data=data, post_process=post_process, **kwargs
    )

    is_unseen_task = False
    if self.unseen_task_detect:

        try:
            if callable(self.unseen_task_detect):
                unseen_task_detect_algorithm = self.unseen_task_detect()
            else:
                unseen_task_detect_algorithm = ClassFactory.get_cls(
                    ClassType.UTD, self.unseen_task_detect
                )()
        except ValueError as err:
            self.log.error(&#34;Lifelong learning &#34;
                           &#34;Inference [UTD] : {}&#34;.format(err))
        else:
            is_unseen_task = unseen_task_detect_algorithm(
                tasks=tasks, result=res, **self.unseen_task_detect_param
            )
    return res, is_unseen_task, tasks</code></pre>
</details>
</dd>
<dt id="sedna.core.lifelong_learning.lifelong_learning.LifelongLearning.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, train_data, valid_data=None, post_process=None, action='initial', **train_param)</span>
</code></dt>
<dd>
<div class="desc">knowledge update by input data<p>
    <br>:param train_data: data use to train model
    <br>:param valid_data: data use to valid model
    <br>:param post_process: callback function
    <br>:param action: initial - kb init, update - kb incremental update</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self, train_data,
          valid_data=None,
          post_process=None,
          action=&#34;initial&#34;,
          **kwargs):
    &#34;&#34;&#34;
    :param train_data: data use to train model
    :param valid_data: data use to valid model
    :param post_process: callback function
    :param action: initial - kb init, update - kb incremental update
    &#34;&#34;&#34;

    callback_func = None
    if post_process is not None:
        callback_func = ClassFactory.get_cls(
            ClassType.CALLBACK, post_process)
    res = self.estimator.train(
        train_data=train_data,
        valid_data=valid_data,
        **kwargs
    )  # todo: Distinguishing incremental update and fully overwrite

    task_index_url = self.estimator.estimator.task_index_url
    task_index = joblib.load(task_index_url)

    extractor = task_index[&#39;extractor&#39;]
    task_groups = task_index[&#39;task_groups&#39;]

    model_upload_key = {}
    for task in task_groups:
        model_file = task.model.model
        save_model = FileOps.join_path(
            self.config.output_url,
            os.path.basename(model_file)
        )
        if model_file not in model_upload_key:
            model_upload_key[model_file] = FileOps.upload(model_file,
                                                          save_model)
        model_file = model_upload_key[model_file]

        try:
            model = self.kb_server.upload_file(save_model)
        except Exception as err:
            self.log.error(
                f&#34;Upload task model of {model_file} fail: {err}&#34;
            )
            model_obj = set_backend(
                estimator=self.estimator.estimator.base_model
            )
            model = model_obj.load(model_file)
        task.model.model = model

        for _task in task.tasks:
            sample_dir = FileOps.join_path(
                self.config.output_url,
                f&#34;{_task.samples.data_type}_{_task.entry}.sample&#34;)
            task.samples.save(sample_dir)
            try:
                sample_dir = self.kb_server.upload_file(sample_dir)
            except Exception as err:
                self.log.error(
                    f&#34;Upload task samples of {_task.entry} fail: {err}&#34;)
            _task.samples.data_url = sample_dir

    task_info = {
        &#34;task_groups&#34;: task_groups,
        &#34;extractor&#34;: extractor
    }
    fd, name = tempfile.mkstemp()
    joblib.dump(task_info, name)

    index_file = self.kb_server.update_db(name)
    if not index_file:
        self.log.error(f&#34;KB update Fail !&#34;)
        index_file = name
    FileOps.upload(index_file, self.config.task_index)

    task_info_res = self.estimator.model_info(
        self.config.task_index, result=res,
        relpath=self.config.data_path_prefix)
    self.report_task_info(
        None, K8sResourceKindStatus.COMPLETED.value, task_info_res)
    self.log.info(f&#34;Lifelong learning Train task Finished, &#34;
                  f&#34;KB idnex save in {self.config.task_index}&#34;)
    return callback_func(self.estimator, res) if callback_func else res</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="sedna.core.base.JobBase" href="../base.html#sedna.core.base.JobBase">JobBase</a></b></code>:
<ul class="hlist">
<li><code><a title="sedna.core.base.JobBase.get_parameters" href="../base.html#sedna.core.base.JobBase.get_parameters">get_parameters</a></code></li>
<li><code><a title="sedna.core.base.JobBase.initial_hem" href="../base.html#sedna.core.base.JobBase.initial_hem">initial_hem</a></code></li>
<li><code><a title="sedna.core.base.JobBase.model_path" href="../base.html#sedna.core.base.JobBase.model_path">model_path</a></code></li>
<li><code><a title="sedna.core.base.JobBase.parameters" href="../base.html#sedna.core.base.JobBase.parameters">parameters</a></code></li>
<li><code><a title="sedna.core.base.JobBase.report_task_info" href="../base.html#sedna.core.base.JobBase.report_task_info">report_task_info</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="sedna.core.lifelong_learning" href="index.html">sedna.core.lifelong_learning</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="sedna.core.lifelong_learning.lifelong_learning.LifelongLearning" href="#sedna.core.lifelong_learning.lifelong_learning.LifelongLearning">LifelongLearning</a></code></h4>
<ul class="">
<li><code><a title="sedna.core.lifelong_learning.lifelong_learning.LifelongLearning.evaluate" href="#sedna.core.lifelong_learning.lifelong_learning.LifelongLearning.evaluate">evaluate</a></code></li>
<li><code><a title="sedna.core.lifelong_learning.lifelong_learning.LifelongLearning.inference" href="#sedna.core.lifelong_learning.lifelong_learning.LifelongLearning.inference">inference</a></code></li>
<li><code><a title="sedna.core.lifelong_learning.lifelong_learning.LifelongLearning.train" href="#sedna.core.lifelong_learning.lifelong_learning.LifelongLearning.train">train</a></code></li>
<li><code><a title="sedna.core.lifelong_learning.lifelong_learning.LifelongLearning.update" href="#sedna.core.lifelong_learning.lifelong_learning.LifelongLearning.update">update</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>